{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用MXNET训练神经网络来识别MNIST手写集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache MXNet 示例演示了对作为 Amazon SageMaker 高级 Python 库的一部分提供的 Amazon SageMaker sagemaker.mxnet.MXNet 估算器类的使用。它提供了 fit 方法和 deploy 方法，前者用于 Amazon SageMaker 中的模型训练，后者用于在 Amazon SageMaker 中部署生成的模型。在本练习中，将使用 Apache MXNet构建一个神经网络分类器。然后，使用 MNIST 数据库数据集 (Amazon SageMaker 在 S3 存储桶中提供) 来训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化变量,提供包S3存储桶的名称。get_execution_role 函数会检索在创建笔记本实例时创建的 IAM 角色。\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "#Bucket location to save your custom code in tar.gz format.\n",
    "custom_code_upload_location = 's3://your_bucket/customcode/mxnet'\n",
    "\n",
    "#Bucket location where results of model training are saved.\n",
    "model_artifacts_location = 's3://your_bucket/artifacts'\n",
    "\n",
    "#IAM execution role that gives Amazon SageMaker access to resources in your AWS account.\n",
    "#We can use the Amazon SageMaker Python SDK to get the role from our notebook environment. \n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高级 Python 库提供了 MXNet 类，它包含两种方法：fit (用于训练模型) 和 deploy (用于部署模型)。\n",
    "entry_point – 示例仅使用一个源文件 (mnist.py)，已经在笔记本实例上提供此源文件。如果自定义代码包含在一个文件中，则仅指定 entry_point 参数；如果训练代码由多个文件组成，则还要添加 source_dir 参数。\n",
    "注意\n",
    "仅指定自定义代码的源。sagemaker.mxnet.MXNet 对象确定要用于模型训练的 Docker 映像。\n",
    "role – IAM 在代表执行任务 时代入的 Amazon SageMaker 角色。\n",
    "code_location – 希望 fit 方法 (下一步中) 将自定义 Apache MXNet 代码的 tar 存档上传到的 S3 位置。\n",
    "output_path – 标识将模型训练结果 (模型构件) 保存到的 S3 位置。\n",
    "train_instance_count 和 train_instance_type – 指定要用于模型训练的实例的数目和类型。\n",
    "还可以通过指定 local 作为 train_instance_type 的值，并指定 1 作为 train_instance_count 的值，在本地计算机上训练模型。有关本地模式的更多信息，请参阅 Amazon SageMaker Python 开发工具包 中的 https://github.com/aws/sagemaker-python-sdk#local-mode。\n",
    "Hyperparameters – 任何指定来影响模型最终质量的超参数。自定义训练代码将使用这些参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "mnist_estimator = MXNet(entry_point='/home/ec2-user/sample-notebooks/sagemaker-python-sdk/mxnet_mnist/mnist.py',\n",
    "                        role=role,\n",
    "                        output_path=model_artifacts_location,\n",
    "                        code_location=custom_code_upload_location,\n",
    "                        train_instance_count=1, \n",
    "                        train_instance_type='ml.p3.2xlarge',\n",
    "                        hyperparameters={'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用fit方法训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-2018-09-05-08-46-50-756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................\n",
      "\u001b[31m2018-09-05 08:50:24,132 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:24,133 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:24,152 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:25,502 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 1, 'channels': {u'test': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}, u'train': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'hosts': [u'algo-1'], u'network_interface_name': u'ethwe', u'current_host': u'algo-1'}, 'user_script_name': u'mnist.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'test': u'/opt/ml/input/data/test', u'train': u'/opt/ml/input/data/train'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'mnist.py', u'learning_rate': 0.1, u'sagemaker_submit_directory': u's3://sagemaker-kingdee-ml-workshop/customcode/mxnet/sagemaker-mxnet-2018-09-05-08-46-50-756/source/sourcedir.tar.gz', u'sagemaker_region': u'us-west-2', u'sagemaker_enable_cloudwatch_metrics': False, u'sagemaker_job_name': u'sagemaker-mxnet-2018-09-05-08-46-50-756', u'sagemaker_container_log_level': 20}, 'hosts': [u'algo-1'], 'job_name': 'sagemaker-mxnet-2018-09-05-08-46-50-756', '_ps_port': 8000, 'user_script_archive': u's3://sagemaker-kingdee-ml-workshop/customcode/mxnet/sagemaker-mxnet-2018-09-05-08-46-50-756/source/sourcedir.tar.gz', '_scheduler_host': u'algo-1', 'sagemaker_region': u'us-west-2', '_scheduler_ip': '10.32.0.4', 'input_dir': '/opt/ml/input', 'user_requirements_file': None, 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 8, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-kingdee-ml-workshop/customcode/mxnet/sagemaker-mxnet-2018-09-05-08-46-50-756/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:26,236 INFO - mxnet_container.train - Starting distributed training task\u001b[0m\n",
      "\u001b[31m/opt/ml/code/mnist.py:13: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  labels = np.fromstring(flbl.read(), dtype=np.int8)\u001b[0m\n",
      "\u001b[31m/opt/ml/code/mnist.py:16: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  images = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(labels), rows, cols)\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,123 INFO - root - Epoch[0] Batch [100]#011Speed: 125617.08 samples/sec#011accuracy=0.113267\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,197 INFO - root - Epoch[0] Batch [200]#011Speed: 134309.27 samples/sec#011accuracy=0.112500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,279 INFO - root - Epoch[0] Batch [300]#011Speed: 122777.61 samples/sec#011accuracy=0.113600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,368 INFO - root - Epoch[0] Batch [400]#011Speed: 113089.99 samples/sec#011accuracy=0.107500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,447 INFO - root - Epoch[0] Batch [500]#011Speed: 127242.79 samples/sec#011accuracy=0.115900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,526 INFO - root - Epoch[0] Train-accuracy=0.233939\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,527 INFO - root - Epoch[0] Time cost=0.502\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,591 INFO - root - Epoch[0] Validation-accuracy=0.335600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,688 INFO - root - Epoch[1] Batch [100]#011Speed: 104213.30 samples/sec#011accuracy=0.461683\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,776 INFO - root - Epoch[1] Batch [200]#011Speed: 114343.23 samples/sec#011accuracy=0.664900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,860 INFO - root - Epoch[1] Batch [300]#011Speed: 118982.28 samples/sec#011accuracy=0.772500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:36,955 INFO - root - Epoch[1] Batch [400]#011Speed: 105899.65 samples/sec#011accuracy=0.798800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,039 INFO - root - Epoch[1] Batch [500]#011Speed: 119544.20 samples/sec#011accuracy=0.824200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,119 INFO - root - Epoch[1] Train-accuracy=0.841313\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,119 INFO - root - Epoch[1] Time cost=0.528\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,182 INFO - root - Epoch[1] Validation-accuracy=0.838200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,280 INFO - root - Epoch[2] Batch [100]#011Speed: 103735.44 samples/sec#011accuracy=0.860594\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,378 INFO - root - Epoch[2] Batch [200]#011Speed: 102484.32 samples/sec#011accuracy=0.871600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,473 INFO - root - Epoch[2] Batch [300]#011Speed: 105184.46 samples/sec#011accuracy=0.886400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,557 INFO - root - Epoch[2] Batch [400]#011Speed: 119786.26 samples/sec#011accuracy=0.895000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,642 INFO - root - Epoch[2] Batch [500]#011Speed: 117307.77 samples/sec#011accuracy=0.905600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,723 INFO - root - Epoch[2] Train-accuracy=0.912323\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,723 INFO - root - Epoch[2] Time cost=0.541\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,788 INFO - root - Epoch[2] Validation-accuracy=0.911000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,874 INFO - root - Epoch[3] Batch [100]#011Speed: 118369.81 samples/sec#011accuracy=0.922178\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:37,996 INFO - root - Epoch[3] Batch [200]#011Speed: 81629.99 samples/sec#011accuracy=0.923600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,080 INFO - root - Epoch[3] Batch [300]#011Speed: 120182.35 samples/sec#011accuracy=0.928800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,168 INFO - root - Epoch[3] Batch [400]#011Speed: 113027.51 samples/sec#011accuracy=0.930300\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,248 INFO - root - Epoch[3] Batch [500]#011Speed: 125497.56 samples/sec#011accuracy=0.936900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,332 INFO - root - Epoch[3] Train-accuracy=0.935758\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,333 INFO - root - Epoch[3] Time cost=0.545\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,395 INFO - root - Epoch[3] Validation-accuracy=0.936400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,481 INFO - root - Epoch[4] Batch [100]#011Speed: 118052.64 samples/sec#011accuracy=0.944158\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,576 INFO - root - Epoch[4] Batch [200]#011Speed: 104434.12 samples/sec#011accuracy=0.943200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,662 INFO - root - Epoch[4] Batch [300]#011Speed: 117511.54 samples/sec#011accuracy=0.947100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,754 INFO - root - Epoch[4] Batch [400]#011Speed: 109133.16 samples/sec#011accuracy=0.947200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,839 INFO - root - Epoch[4] Batch [500]#011Speed: 117602.80 samples/sec#011accuracy=0.951400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,926 INFO - root - Epoch[4] Train-accuracy=0.949798\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,926 INFO - root - Epoch[4] Time cost=0.531\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:38,990 INFO - root - Epoch[4] Validation-accuracy=0.949500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,079 INFO - root - Epoch[5] Batch [100]#011Speed: 114529.00 samples/sec#011accuracy=0.954554\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,160 INFO - root - Epoch[5] Batch [200]#011Speed: 123453.75 samples/sec#011accuracy=0.953800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,244 INFO - root - Epoch[5] Batch [300]#011Speed: 119461.47 samples/sec#011accuracy=0.958900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,335 INFO - root - Epoch[5] Batch [400]#011Speed: 110305.88 samples/sec#011accuracy=0.958300\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,421 INFO - root - Epoch[5] Batch [500]#011Speed: 117040.00 samples/sec#011accuracy=0.961600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,505 INFO - root - Epoch[5] Train-accuracy=0.958081\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,505 INFO - root - Epoch[5] Time cost=0.515\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,568 INFO - root - Epoch[5] Validation-accuracy=0.956200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,656 INFO - root - Epoch[6] Batch [100]#011Speed: 114716.01 samples/sec#011accuracy=0.962772\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,751 INFO - root - Epoch[6] Batch [200]#011Speed: 105356.20 samples/sec#011accuracy=0.961500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,851 INFO - root - Epoch[6] Batch [300]#011Speed: 101011.34 samples/sec#011accuracy=0.965700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:39,933 INFO - root - Epoch[6] Batch [400]#011Speed: 121973.54 samples/sec#011accuracy=0.966100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,014 INFO - root - Epoch[6] Batch [500]#011Speed: 123803.94 samples/sec#011accuracy=0.967000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,106 INFO - root - Epoch[6] Train-accuracy=0.962727\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,106 INFO - root - Epoch[6] Time cost=0.538\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,171 INFO - root - Epoch[6] Validation-accuracy=0.959100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,263 INFO - root - Epoch[7] Batch [100]#011Speed: 109303.81 samples/sec#011accuracy=0.967822\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,359 INFO - root - Epoch[7] Batch [200]#011Speed: 104258.89 samples/sec#011accuracy=0.969100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,454 INFO - root - Epoch[7] Batch [300]#011Speed: 106510.92 samples/sec#011accuracy=0.969500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,545 INFO - root - Epoch[7] Batch [400]#011Speed: 108991.94 samples/sec#011accuracy=0.972100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,628 INFO - root - Epoch[7] Batch [500]#011Speed: 121399.14 samples/sec#011accuracy=0.972700\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-09-05 08:50:40,719 INFO - root - Epoch[7] Train-accuracy=0.970202\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,719 INFO - root - Epoch[7] Time cost=0.548\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,784 INFO - root - Epoch[7] Validation-accuracy=0.962800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,877 INFO - root - Epoch[8] Batch [100]#011Speed: 108659.04 samples/sec#011accuracy=0.971782\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:40,961 INFO - root - Epoch[8] Batch [200]#011Speed: 118411.92 samples/sec#011accuracy=0.972000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,043 INFO - root - Epoch[8] Batch [300]#011Speed: 122825.78 samples/sec#011accuracy=0.972700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,138 INFO - root - Epoch[8] Batch [400]#011Speed: 105253.09 samples/sec#011accuracy=0.975600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,237 INFO - root - Epoch[8] Batch [500]#011Speed: 101020.10 samples/sec#011accuracy=0.975700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,323 INFO - root - Epoch[8] Train-accuracy=0.973131\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,324 INFO - root - Epoch[8] Time cost=0.540\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,384 INFO - root - Epoch[8] Validation-accuracy=0.964000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,477 INFO - root - Epoch[9] Batch [100]#011Speed: 110310.82 samples/sec#011accuracy=0.974851\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,563 INFO - root - Epoch[9] Batch [200]#011Speed: 116559.60 samples/sec#011accuracy=0.975900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,655 INFO - root - Epoch[9] Batch [300]#011Speed: 109044.36 samples/sec#011accuracy=0.976000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,737 INFO - root - Epoch[9] Batch [400]#011Speed: 122180.68 samples/sec#011accuracy=0.979300\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,818 INFO - root - Epoch[9] Batch [500]#011Speed: 122406.75 samples/sec#011accuracy=0.979700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,898 INFO - root - Epoch[9] Train-accuracy=0.976263\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,898 INFO - root - Epoch[9] Time cost=0.513\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:41,960 INFO - root - Epoch[9] Validation-accuracy=0.966900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,036 INFO - root - Epoch[10] Batch [100]#011Speed: 133700.89 samples/sec#011accuracy=0.978416\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,121 INFO - root - Epoch[10] Batch [200]#011Speed: 117761.96 samples/sec#011accuracy=0.979400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,206 INFO - root - Epoch[10] Batch [300]#011Speed: 117004.41 samples/sec#011accuracy=0.977700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,289 INFO - root - Epoch[10] Batch [400]#011Speed: 120635.87 samples/sec#011accuracy=0.981900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,382 INFO - root - Epoch[10] Batch [500]#011Speed: 108260.22 samples/sec#011accuracy=0.982900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,471 INFO - root - Epoch[10] Train-accuracy=0.978990\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,471 INFO - root - Epoch[10] Time cost=0.511\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,538 INFO - root - Epoch[10] Validation-accuracy=0.968200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,632 INFO - root - Epoch[11] Batch [100]#011Speed: 107526.68 samples/sec#011accuracy=0.981386\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,717 INFO - root - Epoch[11] Batch [200]#011Speed: 117542.16 samples/sec#011accuracy=0.983100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,799 INFO - root - Epoch[11] Batch [300]#011Speed: 123351.72 samples/sec#011accuracy=0.980600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,874 INFO - root - Epoch[11] Batch [400]#011Speed: 132168.59 samples/sec#011accuracy=0.983700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:42,955 INFO - root - Epoch[11] Batch [500]#011Speed: 124301.09 samples/sec#011accuracy=0.985100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,048 INFO - root - Epoch[11] Train-accuracy=0.981515\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,049 INFO - root - Epoch[11] Time cost=0.511\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,112 INFO - root - Epoch[11] Validation-accuracy=0.969400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,210 INFO - root - Epoch[12] Batch [100]#011Speed: 103450.16 samples/sec#011accuracy=0.983168\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,299 INFO - root - Epoch[12] Batch [200]#011Speed: 112528.98 samples/sec#011accuracy=0.984400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,380 INFO - root - Epoch[12] Batch [300]#011Speed: 124800.39 samples/sec#011accuracy=0.983800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,465 INFO - root - Epoch[12] Batch [400]#011Speed: 116705.22 samples/sec#011accuracy=0.985400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,560 INFO - root - Epoch[12] Batch [500]#011Speed: 105886.29 samples/sec#011accuracy=0.987200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,655 INFO - root - Epoch[12] Train-accuracy=0.983434\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,655 INFO - root - Epoch[12] Time cost=0.543\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,717 INFO - root - Epoch[12] Validation-accuracy=0.970400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,812 INFO - root - Epoch[13] Batch [100]#011Speed: 106073.74 samples/sec#011accuracy=0.985644\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,895 INFO - root - Epoch[13] Batch [200]#011Speed: 121077.09 samples/sec#011accuracy=0.985800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:43,971 INFO - root - Epoch[13] Batch [300]#011Speed: 131805.99 samples/sec#011accuracy=0.985800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,058 INFO - root - Epoch[13] Batch [400]#011Speed: 114880.33 samples/sec#011accuracy=0.987000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,139 INFO - root - Epoch[13] Batch [500]#011Speed: 123788.59 samples/sec#011accuracy=0.989200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,230 INFO - root - Epoch[13] Train-accuracy=0.985556\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,230 INFO - root - Epoch[13] Time cost=0.513\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,297 INFO - root - Epoch[13] Validation-accuracy=0.971900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,377 INFO - root - Epoch[14] Batch [100]#011Speed: 127139.03 samples/sec#011accuracy=0.986832\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,454 INFO - root - Epoch[14] Batch [200]#011Speed: 130955.37 samples/sec#011accuracy=0.988000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,532 INFO - root - Epoch[14] Batch [300]#011Speed: 128302.27 samples/sec#011accuracy=0.988700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,617 INFO - root - Epoch[14] Batch [400]#011Speed: 117780.14 samples/sec#011accuracy=0.988500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,706 INFO - root - Epoch[14] Batch [500]#011Speed: 112642.92 samples/sec#011accuracy=0.989600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,800 INFO - root - Epoch[14] Train-accuracy=0.987980\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,800 INFO - root - Epoch[14] Time cost=0.502\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,869 INFO - root - Epoch[14] Validation-accuracy=0.971900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:44,952 INFO - root - Epoch[15] Batch [100]#011Speed: 122761.08 samples/sec#011accuracy=0.988911\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,038 INFO - root - Epoch[15] Batch [200]#011Speed: 116997.56 samples/sec#011accuracy=0.989300\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,125 INFO - root - Epoch[15] Batch [300]#011Speed: 115243.33 samples/sec#011accuracy=0.990100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,213 INFO - root - Epoch[15] Batch [400]#011Speed: 112929.22 samples/sec#011accuracy=0.990200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,299 INFO - root - Epoch[15] Batch [500]#011Speed: 116907.23 samples/sec#011accuracy=0.992100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,377 INFO - root - Epoch[15] Train-accuracy=0.989495\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,377 INFO - root - Epoch[15] Time cost=0.508\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,442 INFO - root - Epoch[15] Validation-accuracy=0.971800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,522 INFO - root - Epoch[16] Batch [100]#011Speed: 128630.83 samples/sec#011accuracy=0.990891\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,612 INFO - root - Epoch[16] Batch [200]#011Speed: 110205.02 samples/sec#011accuracy=0.990900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,693 INFO - root - Epoch[16] Batch [300]#011Speed: 124778.49 samples/sec#011accuracy=0.991500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,786 INFO - root - Epoch[16] Batch [400]#011Speed: 108097.55 samples/sec#011accuracy=0.991100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,869 INFO - root - Epoch[16] Batch [500]#011Speed: 120308.18 samples/sec#011accuracy=0.992800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,948 INFO - root - Epoch[16] Train-accuracy=0.990909\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:45,948 INFO - root - Epoch[16] Time cost=0.506\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,012 INFO - root - Epoch[16] Validation-accuracy=0.972300\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,089 INFO - root - Epoch[17] Batch [100]#011Speed: 132054.98 samples/sec#011accuracy=0.991881\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,177 INFO - root - Epoch[17] Batch [200]#011Speed: 113192.53 samples/sec#011accuracy=0.991900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,261 INFO - root - Epoch[17] Batch [300]#011Speed: 119434.25 samples/sec#011accuracy=0.992600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,350 INFO - root - Epoch[17] Batch [400]#011Speed: 113241.12 samples/sec#011accuracy=0.992100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,436 INFO - root - Epoch[17] Batch [500]#011Speed: 115658.99 samples/sec#011accuracy=0.993900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,526 INFO - root - Epoch[17] Train-accuracy=0.992323\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,526 INFO - root - Epoch[17] Time cost=0.514\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,590 INFO - root - Epoch[17] Validation-accuracy=0.972700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,680 INFO - root - Epoch[18] Batch [100]#011Speed: 112837.77 samples/sec#011accuracy=0.993762\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,773 INFO - root - Epoch[18] Batch [200]#011Speed: 107750.71 samples/sec#011accuracy=0.993200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,860 INFO - root - Epoch[18] Batch [300]#011Speed: 114715.69 samples/sec#011accuracy=0.993400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:46,941 INFO - root - Epoch[18] Batch [400]#011Speed: 124091.10 samples/sec#011accuracy=0.993100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,023 INFO - root - Epoch[18] Batch [500]#011Speed: 122024.28 samples/sec#011accuracy=0.995000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,122 INFO - root - Epoch[18] Train-accuracy=0.993636\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,123 INFO - root - Epoch[18] Time cost=0.533\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,188 INFO - root - Epoch[18] Validation-accuracy=0.972900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,273 INFO - root - Epoch[19] Batch [100]#011Speed: 119832.46 samples/sec#011accuracy=0.995050\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,368 INFO - root - Epoch[19] Batch [200]#011Speed: 105433.00 samples/sec#011accuracy=0.993900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,465 INFO - root - Epoch[19] Batch [300]#011Speed: 103320.70 samples/sec#011accuracy=0.994600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,560 INFO - root - Epoch[19] Batch [400]#011Speed: 104847.12 samples/sec#011accuracy=0.994000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,659 INFO - root - Epoch[19] Batch [500]#011Speed: 101540.52 samples/sec#011accuracy=0.995800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,751 INFO - root - Epoch[19] Train-accuracy=0.994343\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,751 INFO - root - Epoch[19] Time cost=0.563\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,815 INFO - root - Epoch[19] Validation-accuracy=0.973700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:47,914 INFO - root - Epoch[20] Batch [100]#011Speed: 101907.63 samples/sec#011accuracy=0.996040\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,010 INFO - root - Epoch[20] Batch [200]#011Speed: 104310.23 samples/sec#011accuracy=0.994700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,095 INFO - root - Epoch[20] Batch [300]#011Speed: 118151.41 samples/sec#011accuracy=0.996100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,176 INFO - root - Epoch[20] Batch [400]#011Speed: 124313.24 samples/sec#011accuracy=0.995400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,254 INFO - root - Epoch[20] Batch [500]#011Speed: 128690.42 samples/sec#011accuracy=0.997100\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,339 INFO - root - Epoch[20] Train-accuracy=0.995758\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,339 INFO - root - Epoch[20] Time cost=0.524\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,400 INFO - root - Epoch[20] Validation-accuracy=0.973500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,483 INFO - root - Epoch[21] Batch [100]#011Speed: 121312.07 samples/sec#011accuracy=0.996931\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,566 INFO - root - Epoch[21] Batch [200]#011Speed: 121831.11 samples/sec#011accuracy=0.995300\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,664 INFO - root - Epoch[21] Batch [300]#011Speed: 101739.78 samples/sec#011accuracy=0.996500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,745 INFO - root - Epoch[21] Batch [400]#011Speed: 123231.76 samples/sec#011accuracy=0.995700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,847 INFO - root - Epoch[21] Batch [500]#011Speed: 98864.90 samples/sec#011accuracy=0.997300\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,927 INFO - root - Epoch[21] Train-accuracy=0.996667\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,927 INFO - root - Epoch[21] Time cost=0.527\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:48,991 INFO - root - Epoch[21] Validation-accuracy=0.973700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,086 INFO - root - Epoch[22] Batch [100]#011Speed: 106139.23 samples/sec#011accuracy=0.997921\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,184 INFO - root - Epoch[22] Batch [200]#011Speed: 102322.81 samples/sec#011accuracy=0.995700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,279 INFO - root - Epoch[22] Batch [300]#011Speed: 105173.38 samples/sec#011accuracy=0.997500\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,363 INFO - root - Epoch[22] Batch [400]#011Speed: 120531.17 samples/sec#011accuracy=0.996300\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,443 INFO - root - Epoch[22] Batch [500]#011Speed: 124758.07 samples/sec#011accuracy=0.997900\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,527 INFO - root - Epoch[22] Train-accuracy=0.996768\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,527 INFO - root - Epoch[22] Time cost=0.536\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,590 INFO - root - Epoch[22] Validation-accuracy=0.973800\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,677 INFO - root - Epoch[23] Batch [100]#011Speed: 115866.67 samples/sec#011accuracy=0.998119\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,766 INFO - root - Epoch[23] Batch [200]#011Speed: 113164.44 samples/sec#011accuracy=0.996300\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,852 INFO - root - Epoch[23] Batch [300]#011Speed: 115939.38 samples/sec#011accuracy=0.998000\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:49,944 INFO - root - Epoch[23] Batch [400]#011Speed: 109272.77 samples/sec#011accuracy=0.996700\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,026 INFO - root - Epoch[23] Batch [500]#011Speed: 122874.00 samples/sec#011accuracy=0.998400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,108 INFO - root - Epoch[23] Train-accuracy=0.997576\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,108 INFO - root - Epoch[23] Time cost=0.519\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,171 INFO - root - Epoch[23] Validation-accuracy=0.973600\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,258 INFO - root - Epoch[24] Batch [100]#011Speed: 117042.61 samples/sec#011accuracy=0.998614\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,346 INFO - root - Epoch[24] Batch [200]#011Speed: 113675.09 samples/sec#011accuracy=0.997200\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,436 INFO - root - Epoch[24] Batch [300]#011Speed: 110794.52 samples/sec#011accuracy=0.998400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,534 INFO - root - Epoch[24] Batch [400]#011Speed: 102737.86 samples/sec#011accuracy=0.997400\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,621 INFO - root - Epoch[24] Batch [500]#011Speed: 115015.16 samples/sec#011accuracy=0.998700\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-09-05 08:50:50,704 INFO - root - Epoch[24] Train-accuracy=0.998283\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,704 INFO - root - Epoch[24] Time cost=0.534\u001b[0m\n",
      "\u001b[31m2018-09-05 08:50:50,770 INFO - root - Epoch[24] Validation-accuracy=0.974000\u001b[0m\n",
      "\n",
      "Billable seconds: 161\n",
      "CPU times: user 512 ms, sys: 16 ms, total: 528 ms\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "train_data_location = 's3://sagemaker-sample-data-{}/mxnet/mnist/train'.format(region)\n",
    "test_data_location = 's3://sagemaker-sample-data-{}/mxnet/mnist/test'.format(region)\n",
    "\n",
    "mnist_estimator.fit({'train': train_data_location, 'test': test_data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 deploy 方法部署模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-mxnet-2018-09-05-08-46-50-756\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-mxnet-2018-09-05-08-46-50-756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------!CPU times: user 248 ms, sys: 20 ms, total: 268 ms\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = mnist_estimator.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提供了一个 HTML 画布，可用来使用鼠标绘制一个数字。测试代码将此图像发送到模型以进行推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/Javascript\">\n",
       "    var pixels = [];\n",
       "    for (var i = 0; i < 28*28; i++) pixels[i] = 0;\n",
       "    var click = 0;\n",
       "\n",
       "    var canvas = document.querySelector(\"canvas\");\n",
       "    canvas.addEventListener(\"mousemove\", function(e){\n",
       "        if (e.buttons == 1) {\n",
       "            click = 1;\n",
       "            canvas.getContext(\"2d\").fillStyle = \"rgb(0,0,0)\";\n",
       "            canvas.getContext(\"2d\").fillRect(e.offsetX, e.offsetY, 8, 8);\n",
       "            x = Math.floor(e.offsetY * 0.2);\n",
       "            y = Math.floor(e.offsetX * 0.2) + 1;\n",
       "            for (var dy = 0; dy < 2; dy++){\n",
       "                for (var dx = 0; dx < 2; dx++){\n",
       "                    if ((x + dx < 28) && (y + dy < 28)){\n",
       "                        pixels[(y+dy)+(x+dx)*28] = 1;\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "        } else {\n",
       "            if (click == 1) set_value();\n",
       "            click = 0;\n",
       "        }\n",
       "    });\n",
       "    function clear_value(){\n",
       "        canvas.getContext(\"2d\").fillStyle = \"rgb(255,255,255)\";\n",
       "        canvas.getContext(\"2d\").fillRect(0, 0, 140, 140);\n",
       "        for (var i = 0; i < 28*28; i++) pixels[i] = 0;\n",
       "    }\n",
       "    \n",
       "    function set_value(){\n",
       "        var result = \"[[\"\n",
       "        for (var i = 0; i < 28; i++) {\n",
       "            result += \"[\"\n",
       "            for (var j = 0; j < 28; j++) {\n",
       "                result += pixels [i * 28 + j]\n",
       "                if (j < 27) {\n",
       "                    result += \", \"\n",
       "                }\n",
       "            }\n",
       "            result += \"]\"\n",
       "            if (i < 27) {\n",
       "                result += \", \"\n",
       "            }\n",
       "        }\n",
       "        result += \"]]\"\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute(\"data = \" + result)\n",
       "    }\n",
       "</script>\n",
       "<table>\n",
       "<td style=\"border-style: none;\">\n",
       "<div style=\"border: solid 2px #666; width: 143px; height: 144px;\">\n",
       "<canvas width=\"140\" height=\"140\"></canvas>\n",
       "</div></td>\n",
       "<td style=\"border-style: none;\">\n",
       "<button onclick=\"clear_value()\">Clear</button>\n",
       "</td>\n",
       "</table>\n",
       "\n",
       "<!-- This work has been modified from the original and is licensed under the Apache 2.0 License. -->\n",
       "\n",
       "<!--\n",
       "                                     Apache License\n",
       "                           Version 2.0, January 2004\n",
       "                        http://www.apache.org/licenses/\n",
       "\n",
       "   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n",
       "\n",
       "   1. Definitions.\n",
       "\n",
       "      \"License\" shall mean the terms and conditions for use, reproduction,\n",
       "      and distribution as defined by Sections 1 through 9 of this document.\n",
       "\n",
       "      \"Licensor\" shall mean the copyright owner or entity authorized by\n",
       "      the copyright owner that is granting the License.\n",
       "\n",
       "      \"Legal Entity\" shall mean the union of the acting entity and all\n",
       "      other entities that control, are controlled by, or are under common\n",
       "      control with that entity. For the purposes of this definition,\n",
       "      \"control\" means (i) the power, direct or indirect, to cause the\n",
       "      direction or management of such entity, whether by contract or\n",
       "      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n",
       "      outstanding shares, or (iii) beneficial ownership of such entity.\n",
       "\n",
       "      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n",
       "      exercising permissions granted by this License.\n",
       "\n",
       "      \"Source\" form shall mean the preferred form for making modifications,\n",
       "      including but not limited to software source code, documentation\n",
       "      source, and configuration files.\n",
       "\n",
       "      \"Object\" form shall mean any form resulting from mechanical\n",
       "      transformation or translation of a Source form, including but\n",
       "      not limited to compiled object code, generated documentation,\n",
       "      and conversions to other media types.\n",
       "\n",
       "      \"Work\" shall mean the work of authorship, whether in Source or\n",
       "      Object form, made available under the License, as indicated by a\n",
       "      copyright notice that is included in or attached to the work\n",
       "      (an example is provided in the Appendix below).\n",
       "\n",
       "      \"Derivative Works\" shall mean any work, whether in Source or Object\n",
       "      form, that is based on (or derived from) the Work and for which the\n",
       "      editorial revisions, annotations, elaborations, or other modifications\n",
       "      represent, as a whole, an original work of authorship. For the purposes\n",
       "      of this License, Derivative Works shall not include works that remain\n",
       "      separable from, or merely link (or bind by name) to the interfaces of,\n",
       "      the Work and Derivative Works thereof.\n",
       "\n",
       "      \"Contribution\" shall mean any work of authorship, including\n",
       "      the original version of the Work and any modifications or additions\n",
       "      to that Work or Derivative Works thereof, that is intentionally\n",
       "      submitted to Licensor for inclusion in the Work by the copyright owner\n",
       "      or by an individual or Legal Entity authorized to submit on behalf of\n",
       "      the copyright owner. For the purposes of this definition, \"submitted\"\n",
       "      means any form of electronic, verbal, or written communication sent\n",
       "      to the Licensor or its representatives, including but not limited to\n",
       "      communication on electronic mailing lists, source code control systems,\n",
       "      and issue tracking systems that are managed by, or on behalf of, the\n",
       "      Licensor for the purpose of discussing and improving the Work, but\n",
       "      excluding communication that is conspicuously marked or otherwise\n",
       "      designated in writing by the copyright owner as \"Not a Contribution.\"\n",
       "\n",
       "      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n",
       "      on behalf of whom a Contribution has been received by Licensor and\n",
       "      subsequently incorporated within the Work.\n",
       "\n",
       "   2. Grant of Copyright License. Subject to the terms and conditions of\n",
       "      this License, each Contributor hereby grants to You a perpetual,\n",
       "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
       "      copyright license to reproduce, prepare Derivative Works of,\n",
       "      publicly display, publicly perform, sublicense, and distribute the\n",
       "      Work and such Derivative Works in Source or Object form.\n",
       "\n",
       "   3. Grant of Patent License. Subject to the terms and conditions of\n",
       "      this License, each Contributor hereby grants to You a perpetual,\n",
       "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
       "      (except as stated in this section) patent license to make, have made,\n",
       "      use, offer to sell, sell, import, and otherwise transfer the Work,\n",
       "      where such license applies only to those patent claims licensable\n",
       "      by such Contributor that are necessarily infringed by their\n",
       "      Contribution(s) alone or by combination of their Contribution(s)\n",
       "      with the Work to which such Contribution(s) was submitted. If You\n",
       "      institute patent litigation against any entity (including a\n",
       "      cross-claim or counterclaim in a lawsuit) alleging that the Work\n",
       "      or a Contribution incorporated within the Work constitutes direct\n",
       "      or contributory patent infringement, then any patent licenses\n",
       "      granted to You under this License for that Work shall terminate\n",
       "      as of the date such litigation is filed.\n",
       "\n",
       "   4. Redistribution. You may reproduce and distribute copies of the\n",
       "      Work or Derivative Works thereof in any medium, with or without\n",
       "      modifications, and in Source or Object form, provided that You\n",
       "      meet the following conditions:\n",
       "\n",
       "      (a) You must give any other recipients of the Work or\n",
       "          Derivative Works a copy of this License; and\n",
       "\n",
       "      (b) You must cause any modified files to carry prominent notices\n",
       "          stating that You changed the files; and\n",
       "\n",
       "      (c) You must retain, in the Source form of any Derivative Works\n",
       "          that You distribute, all copyright, patent, trademark, and\n",
       "          attribution notices from the Source form of the Work,\n",
       "          excluding those notices that do not pertain to any part of\n",
       "          the Derivative Works; and\n",
       "\n",
       "      (d) If the Work includes a \"NOTICE\" text file as part of its\n",
       "          distribution, then any Derivative Works that You distribute must\n",
       "          include a readable copy of the attribution notices contained\n",
       "          within such NOTICE file, excluding those notices that do not\n",
       "          pertain to any part of the Derivative Works, in at least one\n",
       "          of the following places: within a NOTICE text file distributed\n",
       "          as part of the Derivative Works; within the Source form or\n",
       "          documentation, if provided along with the Derivative Works; or,\n",
       "          within a display generated by the Derivative Works, if and\n",
       "          wherever such third-party notices normally appear. The contents\n",
       "          of the NOTICE file are for informational purposes only and\n",
       "          do not modify the License. You may add Your own attribution\n",
       "          notices within Derivative Works that You distribute, alongside\n",
       "          or as an addendum to the NOTICE text from the Work, provided\n",
       "          that such additional attribution notices cannot be construed\n",
       "          as modifying the License.\n",
       "\n",
       "      You may add Your own copyright statement to Your modifications and\n",
       "      may provide additional or different license terms and conditions\n",
       "      for use, reproduction, or distribution of Your modifications, or\n",
       "      for any such Derivative Works as a whole, provided Your use,\n",
       "      reproduction, and distribution of the Work otherwise complies with\n",
       "      the conditions stated in this License.\n",
       "\n",
       "   5. Submission of Contributions. Unless You explicitly state otherwise,\n",
       "      any Contribution intentionally submitted for inclusion in the Work\n",
       "      by You to the Licensor shall be under the terms and conditions of\n",
       "      this License, without any additional terms or conditions.\n",
       "      Notwithstanding the above, nothing herein shall supersede or modify\n",
       "      the terms of any separate license agreement you may have executed\n",
       "      with Licensor regarding such Contributions.\n",
       "\n",
       "   6. Trademarks. This License does not grant permission to use the trade\n",
       "      names, trademarks, service marks, or product names of the Licensor,\n",
       "      except as required for reasonable and customary use in describing the\n",
       "      origin of the Work and reproducing the content of the NOTICE file.\n",
       "\n",
       "   7. Disclaimer of Warranty. Unless required by applicable law or\n",
       "      agreed to in writing, Licensor provides the Work (and each\n",
       "      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n",
       "      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
       "      implied, including, without limitation, any warranties or conditions\n",
       "      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n",
       "      PARTICULAR PURPOSE. You are solely responsible for determining the\n",
       "      appropriateness of using or redistributing the Work and assume any\n",
       "      risks associated with Your exercise of permissions under this License.\n",
       "\n",
       "   8. Limitation of Liability. In no event and under no legal theory,\n",
       "      whether in tort (including negligence), contract, or otherwise,\n",
       "      unless required by applicable law (such as deliberate and grossly\n",
       "      negligent acts) or agreed to in writing, shall any Contributor be\n",
       "      liable to You for damages, including any direct, indirect, special,\n",
       "      incidental, or consequential damages of any character arising as a\n",
       "      result of this License or out of the use or inability to use the\n",
       "      Work (including but not limited to damages for loss of goodwill,\n",
       "      work stoppage, computer failure or malfunction, or any and all\n",
       "      other commercial damages or losses), even if such Contributor\n",
       "      has been advised of the possibility of such damages.\n",
       "\n",
       "   9. Accepting Warranty or Additional Liability. While redistributing\n",
       "      the Work or Derivative Works thereof, You may choose to offer,\n",
       "      and charge a fee for, acceptance of support, warranty, indemnity,\n",
       "      or other liability obligations and/or rights consistent with this\n",
       "      License. However, in accepting such obligations, You may act only\n",
       "      on Your own behalf and on Your sole responsibility, not on behalf\n",
       "      of any other Contributor, and only if You agree to indemnify,\n",
       "      defend, and hold each Contributor harmless for any liability\n",
       "      incurred by, or claims asserted against, such Contributor by reason\n",
       "      of your accepting any such warranty or additional liability.\n",
       "\n",
       "   END OF TERMS AND CONDITIONS\n",
       "\n",
       "   APPENDIX: How to apply the Apache License to your work.\n",
       "\n",
       "      To apply the Apache License to your work, attach the following\n",
       "      boilerplate notice, with the fields enclosed by brackets \"{}\"\n",
       "      replaced with your own identifying information. (Don't include\n",
       "      the brackets!)  The text should be enclosed in the appropriate\n",
       "      comment syntax for the file format. We also recommend that a\n",
       "      file or class name and description of purpose be included on the\n",
       "      same \"printed page\" as the copyright notice for easier\n",
       "      identification within third-party archives.\n",
       "\n",
       "   Copyright {yyyy} {name of copyright owner}\n",
       "\n",
       "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "   you may not use this file except in compliance with the License.\n",
       "   You may obtain a copy of the License at\n",
       "\n",
       "       http://www.apache.org/licenses/LICENSE-2.0\n",
       "\n",
       "   Unless required by applicable law or agreed to in writing, software\n",
       "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "   See the License for the specific language governing permissions and\n",
       "   limitations under the License.\n",
       "-->\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open(\"/home/ec2-user/sample-notebooks/sagemaker-python-sdk/mxnet_mnist/input.html\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行 predict 方法以从模型获取推理。\n",
    "Raw prediction result (原始预测结果) 是模型作为推理返回的 10 个概率值的列表，对应于数字 0 到 9。在这些值中，输入数字为 7，它基于最高概率值 (0.7383657097816467)。\n",
    "按顺序列出这些值，每个数字 (0 到 9) 对应一个值。模型已向它添加标签并返回 Labeled predictions (标记的预测)。\n",
    "根据最高概率，我们的代码返回了 Most likely answer (最有可能的答案) (数字 7)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw prediction result:\n",
      "[[5.544194209505804e-06, 1.3221169714583425e-09, 5.428920849226415e-05, 0.00010763142927316949, 1.2365965456478945e-12, 7.250346811815689e-08, 2.580872120834174e-14, 0.9955496788024902, 1.7152629538941255e-07, 0.004282642621546984]]\n",
      "Labeled predictions: \n",
      "[(0, 5.544194209505804e-06), (1, 1.3221169714583425e-09), (2, 5.428920849226415e-05), (3, 0.00010763142927316949), (4, 1.2365965456478945e-12), (5, 7.250346811815689e-08), (6, 2.580872120834174e-14), (7, 0.9955496788024902), (8, 1.7152629538941255e-07), (9, 0.004282642621546984)]\n",
      "Most likely answer: (7, 0.9955496788024902)\n"
     ]
    }
   ],
   "source": [
    "response = predictor.predict(data)\n",
    "print('Raw prediction result:')\n",
    "print(response)\n",
    "\n",
    "labeled_predictions = list(zip(range(10), response[0]))\n",
    "print('Labeled predictions: ')\n",
    "print(labeled_predictions)\n",
    "\n",
    "labeled_predictions.sort(key=lambda label_and_prob: 1.0 - label_and_prob[1])\n",
    "print('Most likely answer: {}'.format(labeled_predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
