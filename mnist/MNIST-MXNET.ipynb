{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用MXNET训练神经网络来识别MNIST手写集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache MXNet 示例演示了对作为 Amazon SageMaker 高级 Python 库的一部分提供的 Amazon SageMaker sagemaker.mxnet.MXNet 估算器类的使用。它提供了 fit 方法和 deploy 方法，前者用于 Amazon SageMaker 中的模型训练，后者用于在 Amazon SageMaker 中部署生成的模型。在本练习中，将使用 Apache MXNet构建一个神经网络分类器。然后，使用 MNIST 数据库数据集 (Amazon SageMaker 在 S3 存储桶中提供) 来训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化变量,提供包S3存储桶的名称。get_execution_role 函数会检索在创建笔记本实例时创建的 IAM 角色。\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "#Bucket location to save your custom code in tar.gz format.\n",
    "custom_code_upload_location = 's3://your-bucket-name/customcode/mxnet'\n",
    "\n",
    "#Bucket location where results of model training are saved.\n",
    "model_artifacts_location = 's3://your-bucket-name/artifacts'\n",
    "\n",
    "#IAM execution role that gives Amazon SageMaker access to resources in your AWS account.\n",
    "#We can use the Amazon SageMaker Python SDK to get the role from our notebook environment. \n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高级 Python 库提供了 MXNet 类，它包含两种方法：fit (用于训练模型) 和 deploy (用于部署模型)。\n",
    "entry_point – 示例仅使用一个源文件 (mnist.py)，已经在笔记本实例上提供此源文件。如果自定义代码包含在一个文件中，则仅指定 entry_point 参数；如果训练代码由多个文件组成，则还要添加 source_dir 参数。\n",
    "注意\n",
    "仅指定自定义代码的源。sagemaker.mxnet.MXNet 对象确定要用于模型训练的 Docker 映像。\n",
    "role – IAM 在代表执行任务 时代入的 Amazon SageMaker 角色。\n",
    "code_location – 希望 fit 方法 (下一步中) 将自定义 Apache MXNet 代码的 tar 存档上传到的 S3 位置。\n",
    "output_path – 标识将模型训练结果 (模型构件) 保存到的 S3 位置。\n",
    "train_instance_count 和 train_instance_type – 指定要用于模型训练的实例的数目和类型。\n",
    "还可以通过指定 local 作为 train_instance_type 的值，并指定 1 作为 train_instance_count 的值，在本地计算机上训练模型。有关本地模式的更多信息，请参阅 Amazon SageMaker Python 开发工具包 中的 https://github.com/aws/sagemaker-python-sdk#local-mode。\n",
    "Hyperparameters – 任何指定来影响模型最终质量的超参数。自定义训练代码将使用这些参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "mnist_estimator = MXNet(entry_point='/home/ec2-user/sample-notebooks/sagemaker-python-sdk/mxnet_mnist/mnist.py',\n",
    "                        role=role,\n",
    "                        output_path=model_artifacts_location,\n",
    "                        code_location=custom_code_upload_location,\n",
    "                        train_instance_count=1, \n",
    "                        train_instance_type='ml.p3.2xlarge',\n",
    "                        hyperparameters={'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用fit方法训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-2018-09-04-06-48-02-016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................\n",
      "\u001b[31m2018-09-04 06:51:45,659 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:45,659 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:45,679 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:47,280 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 1, 'channels': {u'test': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}, u'train': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'hosts': [u'algo-1'], u'network_interface_name': u'ethwe', u'current_host': u'algo-1'}, 'user_script_name': u'mnist.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'test': u'/opt/ml/input/data/test', u'train': u'/opt/ml/input/data/train'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'mnist.py', u'learning_rate': 0.1, u'sagemaker_submit_directory': u's3://421710401846-sagemaker-us-west-2/customcode/mxnet/sagemaker-mxnet-2018-09-04-06-48-02-016/source/sourcedir.tar.gz', u'sagemaker_region': u'us-west-2', u'sagemaker_enable_cloudwatch_metrics': False, u'sagemaker_job_name': u'sagemaker-mxnet-2018-09-04-06-48-02-016', u'sagemaker_container_log_level': 20}, 'hosts': [u'algo-1'], 'job_name': 'sagemaker-mxnet-2018-09-04-06-48-02-016', '_ps_port': 8000, 'user_script_archive': u's3://421710401846-sagemaker-us-west-2/customcode/mxnet/sagemaker-mxnet-2018-09-04-06-48-02-016/source/sourcedir.tar.gz', '_scheduler_host': u'algo-1', 'sagemaker_region': u'us-west-2', '_scheduler_ip': '10.32.0.4', 'input_dir': '/opt/ml/input', 'user_requirements_file': None, 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 8, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://421710401846-sagemaker-us-west-2/customcode/mxnet/sagemaker-mxnet-2018-09-04-06-48-02-016/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:47,701 INFO - mxnet_container.train - Starting distributed training task\u001b[0m\n",
      "\u001b[31m/opt/ml/code/mnist.py:13: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  labels = np.fromstring(flbl.read(), dtype=np.int8)\u001b[0m\n",
      "\u001b[31m/opt/ml/code/mnist.py:16: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  images = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(labels), rows, cols)\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:56,828 INFO - root - Epoch[0] Batch [100]#011Speed: 131293.97 samples/sec#011accuracy=0.113267\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:56,909 INFO - root - Epoch[0] Batch [200]#011Speed: 122825.78 samples/sec#011accuracy=0.112500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:56,989 INFO - root - Epoch[0] Batch [300]#011Speed: 125602.78 samples/sec#011accuracy=0.113600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,073 INFO - root - Epoch[0] Batch [400]#011Speed: 119146.89 samples/sec#011accuracy=0.107500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,158 INFO - root - Epoch[0] Batch [500]#011Speed: 118440.00 samples/sec#011accuracy=0.115900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,234 INFO - root - Epoch[0] Train-accuracy=0.233939\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,235 INFO - root - Epoch[0] Time cost=0.501\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,301 INFO - root - Epoch[0] Validation-accuracy=0.335600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,394 INFO - root - Epoch[1] Batch [100]#011Speed: 109168.95 samples/sec#011accuracy=0.461683\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,480 INFO - root - Epoch[1] Batch [200]#011Speed: 116029.50 samples/sec#011accuracy=0.664900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,563 INFO - root - Epoch[1] Batch [300]#011Speed: 120454.33 samples/sec#011accuracy=0.772500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,656 INFO - root - Epoch[1] Batch [400]#011Speed: 107877.08 samples/sec#011accuracy=0.798800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,748 INFO - root - Epoch[1] Batch [500]#011Speed: 109452.41 samples/sec#011accuracy=0.824200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,822 INFO - root - Epoch[1] Train-accuracy=0.841313\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,822 INFO - root - Epoch[1] Time cost=0.521\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,880 INFO - root - Epoch[1] Validation-accuracy=0.838200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:57,970 INFO - root - Epoch[2] Batch [100]#011Speed: 112318.95 samples/sec#011accuracy=0.860594\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,063 INFO - root - Epoch[2] Batch [200]#011Speed: 107682.93 samples/sec#011accuracy=0.871600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,143 INFO - root - Epoch[2] Batch [300]#011Speed: 124710.22 samples/sec#011accuracy=0.886400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,228 INFO - root - Epoch[2] Batch [400]#011Speed: 118764.64 samples/sec#011accuracy=0.895000\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,317 INFO - root - Epoch[2] Batch [500]#011Speed: 112569.75 samples/sec#011accuracy=0.905600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,391 INFO - root - Epoch[2] Train-accuracy=0.912323\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,391 INFO - root - Epoch[2] Time cost=0.511\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,451 INFO - root - Epoch[2] Validation-accuracy=0.911000\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,534 INFO - root - Epoch[3] Batch [100]#011Speed: 122116.30 samples/sec#011accuracy=0.922178\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,635 INFO - root - Epoch[3] Batch [200]#011Speed: 99478.78 samples/sec#011accuracy=0.923600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,712 INFO - root - Epoch[3] Batch [300]#011Speed: 130110.00 samples/sec#011accuracy=0.928800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,810 INFO - root - Epoch[3] Batch [400]#011Speed: 102159.57 samples/sec#011accuracy=0.930300\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,897 INFO - root - Epoch[3] Batch [500]#011Speed: 114475.24 samples/sec#011accuracy=0.936900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,976 INFO - root - Epoch[3] Train-accuracy=0.935758\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:58,976 INFO - root - Epoch[3] Time cost=0.524\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,035 INFO - root - Epoch[3] Validation-accuracy=0.936400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,135 INFO - root - Epoch[4] Batch [100]#011Speed: 101713.88 samples/sec#011accuracy=0.944158\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,216 INFO - root - Epoch[4] Batch [200]#011Speed: 123565.40 samples/sec#011accuracy=0.943200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,300 INFO - root - Epoch[4] Batch [300]#011Speed: 119159.75 samples/sec#011accuracy=0.947100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,388 INFO - root - Epoch[4] Batch [400]#011Speed: 113995.17 samples/sec#011accuracy=0.947200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,463 INFO - root - Epoch[4] Batch [500]#011Speed: 133010.21 samples/sec#011accuracy=0.951400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,543 INFO - root - Epoch[4] Train-accuracy=0.949798\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,543 INFO - root - Epoch[4] Time cost=0.507\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,605 INFO - root - Epoch[4] Validation-accuracy=0.949500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,693 INFO - root - Epoch[5] Batch [100]#011Speed: 115441.57 samples/sec#011accuracy=0.954554\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,786 INFO - root - Epoch[5] Batch [200]#011Speed: 107865.70 samples/sec#011accuracy=0.953800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,864 INFO - root - Epoch[5] Batch [300]#011Speed: 129553.79 samples/sec#011accuracy=0.958900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:51:59,944 INFO - root - Epoch[5] Batch [400]#011Speed: 125162.75 samples/sec#011accuracy=0.958300\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,038 INFO - root - Epoch[5] Batch [500]#011Speed: 106424.97 samples/sec#011accuracy=0.961600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,136 INFO - root - Epoch[5] Train-accuracy=0.958081\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,136 INFO - root - Epoch[5] Time cost=0.530\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,196 INFO - root - Epoch[5] Validation-accuracy=0.956200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,281 INFO - root - Epoch[6] Batch [100]#011Speed: 119915.72 samples/sec#011accuracy=0.962772\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,372 INFO - root - Epoch[6] Batch [200]#011Speed: 109628.64 samples/sec#011accuracy=0.961500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,462 INFO - root - Epoch[6] Batch [300]#011Speed: 110803.31 samples/sec#011accuracy=0.965700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,545 INFO - root - Epoch[6] Batch [400]#011Speed: 120644.54 samples/sec#011accuracy=0.966100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,636 INFO - root - Epoch[6] Batch [500]#011Speed: 110623.29 samples/sec#011accuracy=0.967000\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,716 INFO - root - Epoch[6] Train-accuracy=0.962727\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,716 INFO - root - Epoch[6] Time cost=0.519\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,777 INFO - root - Epoch[6] Validation-accuracy=0.959100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,858 INFO - root - Epoch[7] Batch [100]#011Speed: 124667.96 samples/sec#011accuracy=0.967822\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:00,944 INFO - root - Epoch[7] Batch [200]#011Speed: 116941.45 samples/sec#011accuracy=0.969100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,022 INFO - root - Epoch[7] Batch [300]#011Speed: 128949.17 samples/sec#011accuracy=0.969500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,108 INFO - root - Epoch[7] Batch [400]#011Speed: 115997.09 samples/sec#011accuracy=0.972100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,194 INFO - root - Epoch[7] Batch [500]#011Speed: 116443.11 samples/sec#011accuracy=0.972700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,283 INFO - root - Epoch[7] Train-accuracy=0.970202\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,284 INFO - root - Epoch[7] Time cost=0.506\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,345 INFO - root - Epoch[7] Validation-accuracy=0.962800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,432 INFO - root - Epoch[8] Batch [100]#011Speed: 116765.33 samples/sec#011accuracy=0.971782\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,525 INFO - root - Epoch[8] Batch [200]#011Speed: 108192.08 samples/sec#011accuracy=0.972000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-09-04 06:52:01,601 INFO - root - Epoch[8] Batch [300]#011Speed: 131736.86 samples/sec#011accuracy=0.972700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,698 INFO - root - Epoch[8] Batch [400]#011Speed: 103508.88 samples/sec#011accuracy=0.975600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,776 INFO - root - Epoch[8] Batch [500]#011Speed: 127008.52 samples/sec#011accuracy=0.975700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,862 INFO - root - Epoch[8] Train-accuracy=0.973131\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,862 INFO - root - Epoch[8] Time cost=0.516\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:01,923 INFO - root - Epoch[8] Validation-accuracy=0.964000\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,020 INFO - root - Epoch[9] Batch [100]#011Speed: 103963.26 samples/sec#011accuracy=0.974851\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,098 INFO - root - Epoch[9] Batch [200]#011Speed: 128829.56 samples/sec#011accuracy=0.975900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,178 INFO - root - Epoch[9] Batch [300]#011Speed: 125439.00 samples/sec#011accuracy=0.976000\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,261 INFO - root - Epoch[9] Batch [400]#011Speed: 121209.00 samples/sec#011accuracy=0.979300\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,346 INFO - root - Epoch[9] Batch [500]#011Speed: 117756.33 samples/sec#011accuracy=0.979700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,430 INFO - root - Epoch[9] Train-accuracy=0.976263\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,430 INFO - root - Epoch[9] Time cost=0.507\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,488 INFO - root - Epoch[9] Validation-accuracy=0.966900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,570 INFO - root - Epoch[10] Batch [100]#011Speed: 123717.75 samples/sec#011accuracy=0.978416\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,647 INFO - root - Epoch[10] Batch [200]#011Speed: 130903.46 samples/sec#011accuracy=0.979400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,731 INFO - root - Epoch[10] Batch [300]#011Speed: 118555.17 samples/sec#011accuracy=0.977700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,817 INFO - root - Epoch[10] Batch [400]#011Speed: 116657.51 samples/sec#011accuracy=0.981900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,897 INFO - root - Epoch[10] Batch [500]#011Speed: 125154.54 samples/sec#011accuracy=0.982900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,983 INFO - root - Epoch[10] Train-accuracy=0.978990\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:02,983 INFO - root - Epoch[10] Time cost=0.495\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,043 INFO - root - Epoch[10] Validation-accuracy=0.968200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,125 INFO - root - Epoch[11] Batch [100]#011Speed: 123461.38 samples/sec#011accuracy=0.981386\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,210 INFO - root - Epoch[11] Batch [200]#011Speed: 118005.48 samples/sec#011accuracy=0.983100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,301 INFO - root - Epoch[11] Batch [300]#011Speed: 109844.25 samples/sec#011accuracy=0.980600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,377 INFO - root - Epoch[11] Batch [400]#011Speed: 131200.74 samples/sec#011accuracy=0.983700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,453 INFO - root - Epoch[11] Batch [500]#011Speed: 131268.08 samples/sec#011accuracy=0.985100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,545 INFO - root - Epoch[11] Train-accuracy=0.981515\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,545 INFO - root - Epoch[11] Time cost=0.502\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,606 INFO - root - Epoch[11] Validation-accuracy=0.969400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,700 INFO - root - Epoch[12] Batch [100]#011Speed: 108443.56 samples/sec#011accuracy=0.983168\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,787 INFO - root - Epoch[12] Batch [200]#011Speed: 115125.03 samples/sec#011accuracy=0.984400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,871 INFO - root - Epoch[12] Batch [300]#011Speed: 118109.82 samples/sec#011accuracy=0.983800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:03,967 INFO - root - Epoch[12] Batch [400]#011Speed: 105022.22 samples/sec#011accuracy=0.985400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,044 INFO - root - Epoch[12] Batch [500]#011Speed: 128769.84 samples/sec#011accuracy=0.987200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,120 INFO - root - Epoch[12] Train-accuracy=0.983434\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,120 INFO - root - Epoch[12] Time cost=0.514\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,179 INFO - root - Epoch[12] Validation-accuracy=0.970400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,274 INFO - root - Epoch[13] Batch [100]#011Speed: 106257.54 samples/sec#011accuracy=0.985644\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,360 INFO - root - Epoch[13] Batch [200]#011Speed: 117171.44 samples/sec#011accuracy=0.985800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,441 INFO - root - Epoch[13] Batch [300]#011Speed: 123216.56 samples/sec#011accuracy=0.985800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,529 INFO - root - Epoch[13] Batch [400]#011Speed: 114434.95 samples/sec#011accuracy=0.987000\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,606 INFO - root - Epoch[13] Batch [500]#011Speed: 129478.20 samples/sec#011accuracy=0.989200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,690 INFO - root - Epoch[13] Train-accuracy=0.985556\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,691 INFO - root - Epoch[13] Time cost=0.511\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,749 INFO - root - Epoch[13] Validation-accuracy=0.971900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,827 INFO - root - Epoch[14] Batch [100]#011Speed: 129489.80 samples/sec#011accuracy=0.986832\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,913 INFO - root - Epoch[14] Batch [200]#011Speed: 117304.81 samples/sec#011accuracy=0.988000\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:04,995 INFO - root - Epoch[14] Batch [300]#011Speed: 120961.51 samples/sec#011accuracy=0.988700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,079 INFO - root - Epoch[14] Batch [400]#011Speed: 120462.98 samples/sec#011accuracy=0.988500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,170 INFO - root - Epoch[14] Batch [500]#011Speed: 109793.65 samples/sec#011accuracy=0.989600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,255 INFO - root - Epoch[14] Train-accuracy=0.987980\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,255 INFO - root - Epoch[14] Time cost=0.506\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,320 INFO - root - Epoch[14] Validation-accuracy=0.971900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,400 INFO - root - Epoch[15] Batch [100]#011Speed: 125214.32 samples/sec#011accuracy=0.988911\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,489 INFO - root - Epoch[15] Batch [200]#011Speed: 112525.36 samples/sec#011accuracy=0.989300\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,567 INFO - root - Epoch[15] Batch [300]#011Speed: 128424.06 samples/sec#011accuracy=0.990100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,658 INFO - root - Epoch[15] Batch [400]#011Speed: 110588.87 samples/sec#011accuracy=0.990200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,737 INFO - root - Epoch[15] Batch [500]#011Speed: 126387.37 samples/sec#011accuracy=0.992100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,830 INFO - root - Epoch[15] Train-accuracy=0.989495\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,830 INFO - root - Epoch[15] Time cost=0.510\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,890 INFO - root - Epoch[15] Validation-accuracy=0.971800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:05,975 INFO - root - Epoch[16] Batch [100]#011Speed: 118777.42 samples/sec#011accuracy=0.990891\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,072 INFO - root - Epoch[16] Batch [200]#011Speed: 103979.49 samples/sec#011accuracy=0.990900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,159 INFO - root - Epoch[16] Batch [300]#011Speed: 114401.86 samples/sec#011accuracy=0.991500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,240 INFO - root - Epoch[16] Batch [400]#011Speed: 124488.13 samples/sec#011accuracy=0.991100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,330 INFO - root - Epoch[16] Batch [500]#011Speed: 110397.34 samples/sec#011accuracy=0.992800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,418 INFO - root - Epoch[16] Train-accuracy=0.990909\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,418 INFO - root - Epoch[16] Time cost=0.528\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,478 INFO - root - Epoch[16] Validation-accuracy=0.972300\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,561 INFO - root - Epoch[17] Batch [100]#011Speed: 123180.01 samples/sec#011accuracy=0.991881\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,640 INFO - root - Epoch[17] Batch [200]#011Speed: 126014.11 samples/sec#011accuracy=0.991900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,735 INFO - root - Epoch[17] Batch [300]#011Speed: 105475.16 samples/sec#011accuracy=0.992600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,817 INFO - root - Epoch[17] Batch [400]#011Speed: 121527.53 samples/sec#011accuracy=0.992100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,903 INFO - root - Epoch[17] Batch [500]#011Speed: 117075.61 samples/sec#011accuracy=0.993900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,996 INFO - root - Epoch[17] Train-accuracy=0.992323\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:06,996 INFO - root - Epoch[17] Time cost=0.517\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,056 INFO - root - Epoch[17] Validation-accuracy=0.972700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,145 INFO - root - Epoch[18] Batch [100]#011Speed: 114560.60 samples/sec#011accuracy=0.993762\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,227 INFO - root - Epoch[18] Batch [200]#011Speed: 121326.80 samples/sec#011accuracy=0.993200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,323 INFO - root - Epoch[18] Batch [300]#011Speed: 104402.67 samples/sec#011accuracy=0.993400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,408 INFO - root - Epoch[18] Batch [400]#011Speed: 117866.20 samples/sec#011accuracy=0.993100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,487 INFO - root - Epoch[18] Batch [500]#011Speed: 126633.50 samples/sec#011accuracy=0.995000\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,582 INFO - root - Epoch[18] Train-accuracy=0.993636\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,583 INFO - root - Epoch[18] Time cost=0.526\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,645 INFO - root - Epoch[18] Validation-accuracy=0.972900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,733 INFO - root - Epoch[19] Batch [100]#011Speed: 115621.69 samples/sec#011accuracy=0.995050\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,820 INFO - root - Epoch[19] Batch [200]#011Speed: 114640.76 samples/sec#011accuracy=0.993900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,905 INFO - root - Epoch[19] Batch [300]#011Speed: 118420.27 samples/sec#011accuracy=0.994600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:07,989 INFO - root - Epoch[19] Batch [400]#011Speed: 118252.34 samples/sec#011accuracy=0.994000\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,079 INFO - root - Epoch[19] Batch [500]#011Speed: 111542.33 samples/sec#011accuracy=0.995800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,161 INFO - root - Epoch[19] Train-accuracy=0.994343\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,161 INFO - root - Epoch[19] Time cost=0.516\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,222 INFO - root - Epoch[19] Validation-accuracy=0.973700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,311 INFO - root - Epoch[20] Batch [100]#011Speed: 113023.86 samples/sec#011accuracy=0.996040\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,397 INFO - root - Epoch[20] Batch [200]#011Speed: 116537.90 samples/sec#011accuracy=0.994700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,485 INFO - root - Epoch[20] Batch [300]#011Speed: 114563.41 samples/sec#011accuracy=0.996100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,563 INFO - root - Epoch[20] Batch [400]#011Speed: 128072.31 samples/sec#011accuracy=0.995400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,660 INFO - root - Epoch[20] Batch [500]#011Speed: 102545.21 samples/sec#011accuracy=0.997100\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,749 INFO - root - Epoch[20] Train-accuracy=0.995758\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,749 INFO - root - Epoch[20] Time cost=0.527\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,811 INFO - root - Epoch[20] Validation-accuracy=0.973500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,904 INFO - root - Epoch[21] Batch [100]#011Speed: 108288.45 samples/sec#011accuracy=0.996931\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:08,983 INFO - root - Epoch[21] Batch [200]#011Speed: 127050.46 samples/sec#011accuracy=0.995300\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,074 INFO - root - Epoch[21] Batch [300]#011Speed: 110070.25 samples/sec#011accuracy=0.996500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,157 INFO - root - Epoch[21] Batch [400]#011Speed: 120614.01 samples/sec#011accuracy=0.995700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,244 INFO - root - Epoch[21] Batch [500]#011Speed: 114945.19 samples/sec#011accuracy=0.997300\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,337 INFO - root - Epoch[21] Train-accuracy=0.996667\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,337 INFO - root - Epoch[21] Time cost=0.526\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,399 INFO - root - Epoch[21] Validation-accuracy=0.973700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,489 INFO - root - Epoch[22] Batch [100]#011Speed: 112565.52 samples/sec#011accuracy=0.997921\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,576 INFO - root - Epoch[22] Batch [200]#011Speed: 114241.39 samples/sec#011accuracy=0.995700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,665 INFO - root - Epoch[22] Batch [300]#011Speed: 112471.95 samples/sec#011accuracy=0.997500\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,763 INFO - root - Epoch[22] Batch [400]#011Speed: 103160.86 samples/sec#011accuracy=0.996300\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,846 INFO - root - Epoch[22] Batch [500]#011Speed: 120561.66 samples/sec#011accuracy=0.997900\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,929 INFO - root - Epoch[22] Train-accuracy=0.996768\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,929 INFO - root - Epoch[22] Time cost=0.530\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:09,988 INFO - root - Epoch[22] Validation-accuracy=0.973800\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,082 INFO - root - Epoch[23] Batch [100]#011Speed: 107527.78 samples/sec#011accuracy=0.998119\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,180 INFO - root - Epoch[23] Batch [200]#011Speed: 102287.12 samples/sec#011accuracy=0.996300\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,268 INFO - root - Epoch[23] Batch [300]#011Speed: 113576.90 samples/sec#011accuracy=0.998000\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,354 INFO - root - Epoch[23] Batch [400]#011Speed: 116714.64 samples/sec#011accuracy=0.996700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,430 INFO - root - Epoch[23] Batch [500]#011Speed: 130921.03 samples/sec#011accuracy=0.998400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,506 INFO - root - Epoch[23] Train-accuracy=0.997576\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,506 INFO - root - Epoch[23] Time cost=0.519\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,566 INFO - root - Epoch[23] Validation-accuracy=0.973600\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,647 INFO - root - Epoch[24] Batch [100]#011Speed: 124577.98 samples/sec#011accuracy=0.998614\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,734 INFO - root - Epoch[24] Batch [200]#011Speed: 114848.88 samples/sec#011accuracy=0.997200\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,816 INFO - root - Epoch[24] Batch [300]#011Speed: 123629.50 samples/sec#011accuracy=0.998400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,896 INFO - root - Epoch[24] Batch [400]#011Speed: 124953.20 samples/sec#011accuracy=0.997400\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:10,974 INFO - root - Epoch[24] Batch [500]#011Speed: 127779.29 samples/sec#011accuracy=0.998700\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:11,060 INFO - root - Epoch[24] Train-accuracy=0.998283\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:11,060 INFO - root - Epoch[24] Time cost=0.494\u001b[0m\n",
      "\u001b[31m2018-09-04 06:52:11,125 INFO - root - Epoch[24] Validation-accuracy=0.974000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Billable seconds: 157\n",
      "CPU times: user 492 ms, sys: 44 ms, total: 536 ms\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "train_data_location = 's3://sagemaker-sample-data-{}/mxnet/mnist/train'.format(region)\n",
    "test_data_location = 's3://sagemaker-sample-data-{}/mxnet/mnist/test'.format(region)\n",
    "\n",
    "mnist_estimator.fit({'train': train_data_location, 'test': test_data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 deploy 方法部署模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-mxnet-2018-09-04-06-48-02-016\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-mxnet-2018-09-04-06-48-02-016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------!CPU times: user 280 ms, sys: 8 ms, total: 288 ms\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = mnist_estimator.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提供了一个 HTML 画布，可用来使用鼠标绘制一个数字。测试代码将此图像发送到模型以进行推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/Javascript\">\n",
       "    var pixels = [];\n",
       "    for (var i = 0; i < 28*28; i++) pixels[i] = 0;\n",
       "    var click = 0;\n",
       "\n",
       "    var canvas = document.querySelector(\"canvas\");\n",
       "    canvas.addEventListener(\"mousemove\", function(e){\n",
       "        if (e.buttons == 1) {\n",
       "            click = 1;\n",
       "            canvas.getContext(\"2d\").fillStyle = \"rgb(0,0,0)\";\n",
       "            canvas.getContext(\"2d\").fillRect(e.offsetX, e.offsetY, 8, 8);\n",
       "            x = Math.floor(e.offsetY * 0.2);\n",
       "            y = Math.floor(e.offsetX * 0.2) + 1;\n",
       "            for (var dy = 0; dy < 2; dy++){\n",
       "                for (var dx = 0; dx < 2; dx++){\n",
       "                    if ((x + dx < 28) && (y + dy < 28)){\n",
       "                        pixels[(y+dy)+(x+dx)*28] = 1;\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "        } else {\n",
       "            if (click == 1) set_value();\n",
       "            click = 0;\n",
       "        }\n",
       "    });\n",
       "    function clear_value(){\n",
       "        canvas.getContext(\"2d\").fillStyle = \"rgb(255,255,255)\";\n",
       "        canvas.getContext(\"2d\").fillRect(0, 0, 140, 140);\n",
       "        for (var i = 0; i < 28*28; i++) pixels[i] = 0;\n",
       "    }\n",
       "    \n",
       "    function set_value(){\n",
       "        var result = \"[[\"\n",
       "        for (var i = 0; i < 28; i++) {\n",
       "            result += \"[\"\n",
       "            for (var j = 0; j < 28; j++) {\n",
       "                result += pixels [i * 28 + j]\n",
       "                if (j < 27) {\n",
       "                    result += \", \"\n",
       "                }\n",
       "            }\n",
       "            result += \"]\"\n",
       "            if (i < 27) {\n",
       "                result += \", \"\n",
       "            }\n",
       "        }\n",
       "        result += \"]]\"\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute(\"data = \" + result)\n",
       "    }\n",
       "</script>\n",
       "<table>\n",
       "<td style=\"border-style: none;\">\n",
       "<div style=\"border: solid 2px #666; width: 143px; height: 144px;\">\n",
       "<canvas width=\"140\" height=\"140\"></canvas>\n",
       "</div></td>\n",
       "<td style=\"border-style: none;\">\n",
       "<button onclick=\"clear_value()\">Clear</button>\n",
       "</td>\n",
       "</table>\n",
       "\n",
       "<!-- This work has been modified from the original and is licensed under the Apache 2.0 License. -->\n",
       "\n",
       "<!--\n",
       "                                     Apache License\n",
       "                           Version 2.0, January 2004\n",
       "                        http://www.apache.org/licenses/\n",
       "\n",
       "   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n",
       "\n",
       "   1. Definitions.\n",
       "\n",
       "      \"License\" shall mean the terms and conditions for use, reproduction,\n",
       "      and distribution as defined by Sections 1 through 9 of this document.\n",
       "\n",
       "      \"Licensor\" shall mean the copyright owner or entity authorized by\n",
       "      the copyright owner that is granting the License.\n",
       "\n",
       "      \"Legal Entity\" shall mean the union of the acting entity and all\n",
       "      other entities that control, are controlled by, or are under common\n",
       "      control with that entity. For the purposes of this definition,\n",
       "      \"control\" means (i) the power, direct or indirect, to cause the\n",
       "      direction or management of such entity, whether by contract or\n",
       "      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n",
       "      outstanding shares, or (iii) beneficial ownership of such entity.\n",
       "\n",
       "      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n",
       "      exercising permissions granted by this License.\n",
       "\n",
       "      \"Source\" form shall mean the preferred form for making modifications,\n",
       "      including but not limited to software source code, documentation\n",
       "      source, and configuration files.\n",
       "\n",
       "      \"Object\" form shall mean any form resulting from mechanical\n",
       "      transformation or translation of a Source form, including but\n",
       "      not limited to compiled object code, generated documentation,\n",
       "      and conversions to other media types.\n",
       "\n",
       "      \"Work\" shall mean the work of authorship, whether in Source or\n",
       "      Object form, made available under the License, as indicated by a\n",
       "      copyright notice that is included in or attached to the work\n",
       "      (an example is provided in the Appendix below).\n",
       "\n",
       "      \"Derivative Works\" shall mean any work, whether in Source or Object\n",
       "      form, that is based on (or derived from) the Work and for which the\n",
       "      editorial revisions, annotations, elaborations, or other modifications\n",
       "      represent, as a whole, an original work of authorship. For the purposes\n",
       "      of this License, Derivative Works shall not include works that remain\n",
       "      separable from, or merely link (or bind by name) to the interfaces of,\n",
       "      the Work and Derivative Works thereof.\n",
       "\n",
       "      \"Contribution\" shall mean any work of authorship, including\n",
       "      the original version of the Work and any modifications or additions\n",
       "      to that Work or Derivative Works thereof, that is intentionally\n",
       "      submitted to Licensor for inclusion in the Work by the copyright owner\n",
       "      or by an individual or Legal Entity authorized to submit on behalf of\n",
       "      the copyright owner. For the purposes of this definition, \"submitted\"\n",
       "      means any form of electronic, verbal, or written communication sent\n",
       "      to the Licensor or its representatives, including but not limited to\n",
       "      communication on electronic mailing lists, source code control systems,\n",
       "      and issue tracking systems that are managed by, or on behalf of, the\n",
       "      Licensor for the purpose of discussing and improving the Work, but\n",
       "      excluding communication that is conspicuously marked or otherwise\n",
       "      designated in writing by the copyright owner as \"Not a Contribution.\"\n",
       "\n",
       "      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n",
       "      on behalf of whom a Contribution has been received by Licensor and\n",
       "      subsequently incorporated within the Work.\n",
       "\n",
       "   2. Grant of Copyright License. Subject to the terms and conditions of\n",
       "      this License, each Contributor hereby grants to You a perpetual,\n",
       "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
       "      copyright license to reproduce, prepare Derivative Works of,\n",
       "      publicly display, publicly perform, sublicense, and distribute the\n",
       "      Work and such Derivative Works in Source or Object form.\n",
       "\n",
       "   3. Grant of Patent License. Subject to the terms and conditions of\n",
       "      this License, each Contributor hereby grants to You a perpetual,\n",
       "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
       "      (except as stated in this section) patent license to make, have made,\n",
       "      use, offer to sell, sell, import, and otherwise transfer the Work,\n",
       "      where such license applies only to those patent claims licensable\n",
       "      by such Contributor that are necessarily infringed by their\n",
       "      Contribution(s) alone or by combination of their Contribution(s)\n",
       "      with the Work to which such Contribution(s) was submitted. If You\n",
       "      institute patent litigation against any entity (including a\n",
       "      cross-claim or counterclaim in a lawsuit) alleging that the Work\n",
       "      or a Contribution incorporated within the Work constitutes direct\n",
       "      or contributory patent infringement, then any patent licenses\n",
       "      granted to You under this License for that Work shall terminate\n",
       "      as of the date such litigation is filed.\n",
       "\n",
       "   4. Redistribution. You may reproduce and distribute copies of the\n",
       "      Work or Derivative Works thereof in any medium, with or without\n",
       "      modifications, and in Source or Object form, provided that You\n",
       "      meet the following conditions:\n",
       "\n",
       "      (a) You must give any other recipients of the Work or\n",
       "          Derivative Works a copy of this License; and\n",
       "\n",
       "      (b) You must cause any modified files to carry prominent notices\n",
       "          stating that You changed the files; and\n",
       "\n",
       "      (c) You must retain, in the Source form of any Derivative Works\n",
       "          that You distribute, all copyright, patent, trademark, and\n",
       "          attribution notices from the Source form of the Work,\n",
       "          excluding those notices that do not pertain to any part of\n",
       "          the Derivative Works; and\n",
       "\n",
       "      (d) If the Work includes a \"NOTICE\" text file as part of its\n",
       "          distribution, then any Derivative Works that You distribute must\n",
       "          include a readable copy of the attribution notices contained\n",
       "          within such NOTICE file, excluding those notices that do not\n",
       "          pertain to any part of the Derivative Works, in at least one\n",
       "          of the following places: within a NOTICE text file distributed\n",
       "          as part of the Derivative Works; within the Source form or\n",
       "          documentation, if provided along with the Derivative Works; or,\n",
       "          within a display generated by the Derivative Works, if and\n",
       "          wherever such third-party notices normally appear. The contents\n",
       "          of the NOTICE file are for informational purposes only and\n",
       "          do not modify the License. You may add Your own attribution\n",
       "          notices within Derivative Works that You distribute, alongside\n",
       "          or as an addendum to the NOTICE text from the Work, provided\n",
       "          that such additional attribution notices cannot be construed\n",
       "          as modifying the License.\n",
       "\n",
       "      You may add Your own copyright statement to Your modifications and\n",
       "      may provide additional or different license terms and conditions\n",
       "      for use, reproduction, or distribution of Your modifications, or\n",
       "      for any such Derivative Works as a whole, provided Your use,\n",
       "      reproduction, and distribution of the Work otherwise complies with\n",
       "      the conditions stated in this License.\n",
       "\n",
       "   5. Submission of Contributions. Unless You explicitly state otherwise,\n",
       "      any Contribution intentionally submitted for inclusion in the Work\n",
       "      by You to the Licensor shall be under the terms and conditions of\n",
       "      this License, without any additional terms or conditions.\n",
       "      Notwithstanding the above, nothing herein shall supersede or modify\n",
       "      the terms of any separate license agreement you may have executed\n",
       "      with Licensor regarding such Contributions.\n",
       "\n",
       "   6. Trademarks. This License does not grant permission to use the trade\n",
       "      names, trademarks, service marks, or product names of the Licensor,\n",
       "      except as required for reasonable and customary use in describing the\n",
       "      origin of the Work and reproducing the content of the NOTICE file.\n",
       "\n",
       "   7. Disclaimer of Warranty. Unless required by applicable law or\n",
       "      agreed to in writing, Licensor provides the Work (and each\n",
       "      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n",
       "      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
       "      implied, including, without limitation, any warranties or conditions\n",
       "      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n",
       "      PARTICULAR PURPOSE. You are solely responsible for determining the\n",
       "      appropriateness of using or redistributing the Work and assume any\n",
       "      risks associated with Your exercise of permissions under this License.\n",
       "\n",
       "   8. Limitation of Liability. In no event and under no legal theory,\n",
       "      whether in tort (including negligence), contract, or otherwise,\n",
       "      unless required by applicable law (such as deliberate and grossly\n",
       "      negligent acts) or agreed to in writing, shall any Contributor be\n",
       "      liable to You for damages, including any direct, indirect, special,\n",
       "      incidental, or consequential damages of any character arising as a\n",
       "      result of this License or out of the use or inability to use the\n",
       "      Work (including but not limited to damages for loss of goodwill,\n",
       "      work stoppage, computer failure or malfunction, or any and all\n",
       "      other commercial damages or losses), even if such Contributor\n",
       "      has been advised of the possibility of such damages.\n",
       "\n",
       "   9. Accepting Warranty or Additional Liability. While redistributing\n",
       "      the Work or Derivative Works thereof, You may choose to offer,\n",
       "      and charge a fee for, acceptance of support, warranty, indemnity,\n",
       "      or other liability obligations and/or rights consistent with this\n",
       "      License. However, in accepting such obligations, You may act only\n",
       "      on Your own behalf and on Your sole responsibility, not on behalf\n",
       "      of any other Contributor, and only if You agree to indemnify,\n",
       "      defend, and hold each Contributor harmless for any liability\n",
       "      incurred by, or claims asserted against, such Contributor by reason\n",
       "      of your accepting any such warranty or additional liability.\n",
       "\n",
       "   END OF TERMS AND CONDITIONS\n",
       "\n",
       "   APPENDIX: How to apply the Apache License to your work.\n",
       "\n",
       "      To apply the Apache License to your work, attach the following\n",
       "      boilerplate notice, with the fields enclosed by brackets \"{}\"\n",
       "      replaced with your own identifying information. (Don't include\n",
       "      the brackets!)  The text should be enclosed in the appropriate\n",
       "      comment syntax for the file format. We also recommend that a\n",
       "      file or class name and description of purpose be included on the\n",
       "      same \"printed page\" as the copyright notice for easier\n",
       "      identification within third-party archives.\n",
       "\n",
       "   Copyright {yyyy} {name of copyright owner}\n",
       "\n",
       "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "   you may not use this file except in compliance with the License.\n",
       "   You may obtain a copy of the License at\n",
       "\n",
       "       http://www.apache.org/licenses/LICENSE-2.0\n",
       "\n",
       "   Unless required by applicable law or agreed to in writing, software\n",
       "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "   See the License for the specific language governing permissions and\n",
       "   limitations under the License.\n",
       "-->\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open(\"/home/ec2-user/sample-notebooks/sagemaker-python-sdk/mxnet_mnist/input.html\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行 predict 方法以从模型获取推理。\n",
    "Raw prediction result (原始预测结果) 是模型作为推理返回的 10 个概率值的列表，对应于数字 0 到 9。在这些值中，输入数字为 7，它基于最高概率值 (0.7383657097816467)。\n",
    "按顺序列出这些值，每个数字 (0 到 9) 对应一个值。模型已向它添加标签并返回 Labeled predictions (标记的预测)。\n",
    "根据最高概率，我们的代码返回了 Most likely answer (最有可能的答案) (数字 7)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw prediction result:\n",
      "[[1.9354635636335993e-19, 9.862841210406259e-08, 3.8618244713184424e-10, 6.26692853984423e-05, 1.6878833400402193e-12, 5.364214656336161e-16, 1.371284484610375e-23, 0.9999217987060547, 1.411845840237902e-08, 1.536494710308034e-05]]\n",
      "Labeled predictions: \n",
      "[(0, 1.9354635636335993e-19), (1, 9.862841210406259e-08), (2, 3.8618244713184424e-10), (3, 6.26692853984423e-05), (4, 1.6878833400402193e-12), (5, 5.364214656336161e-16), (6, 1.371284484610375e-23), (7, 0.9999217987060547), (8, 1.411845840237902e-08), (9, 1.536494710308034e-05)]\n",
      "Most likely answer: (7, 0.9999217987060547)\n"
     ]
    }
   ],
   "source": [
    "response = predictor.predict(data)\n",
    "print('Raw prediction result:')\n",
    "print(response)\n",
    "\n",
    "labeled_predictions = list(zip(range(10), response[0]))\n",
    "print('Labeled predictions: ')\n",
    "print(labeled_predictions)\n",
    "\n",
    "labeled_predictions.sort(key=lambda label_and_prob: 1.0 - label_and_prob[1])\n",
    "print('Most likely answer: {}'.format(labeled_predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
